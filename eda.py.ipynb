{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Aplicando EDA al dataset Taxi Fare\n",
    "\n",
    "Instalamos las dependencias necesarias para realizar el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (1.2.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from pandas) (2.8.1)\r\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from pandas) (1.20.3)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from pandas) (2021.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: seaborn in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (0.11.1)\r\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from seaborn) (3.4.2)\r\n",
      "Requirement already satisfied: pandas>=0.23 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from seaborn) (1.2.4)\r\n",
      "Requirement already satisfied: numpy>=1.15 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from seaborn) (1.20.3)\r\n",
      "Requirement already satisfied: scipy>=1.0 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from seaborn) (1.6.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (8.2.0)\r\n",
      "Requirement already satisfied: six in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (from pandas>=0.23->seaborn) (2021.1)\r\n",
      "Requirement already satisfied: tqdm in /home/diego/Desktop/general_venv/lib/python3.9/site-packages (4.61.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importamos los módulos a utilizar posteriormente\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# Esto es solo para la visualización en Pycharm\n",
    "sns.set_style(\"ticks\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inicializamos algunas constantes a utilizar\n",
    "\n",
    "* **FILE_PATH:** Contiene la ruta de nuestro dataset.\n",
    "* **EARTH_RADIUS:** Es el valor promedio del radio de la Tierra en kilómetros.\n",
    "* **CHUNK_SIZE:** Indica el tamaño del conjunto de datos que se procesará en cada iteración.\n",
    "* **AVAILABLE_CPUS:** Tiene el número de threads que estarán disponibles en el uso de este cuaderno.\n",
    "* **INITIAL_VALID_COLUMNS:** Tiene los nombres de las columnas que nos interesa cargar en memoria.\n",
    "* **LIMIT_TO_TEST:** El número de chunks que usaremos para realizar algunos gráficos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "('train.csv', 6378.0, 1500000, 11)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_PATH = \"train.csv\"\n",
    "EARTH_RADIUS = 6378.0  # Lo utilizamos en el cálculo de la fórmula de Haversine.\n",
    "CHUNK_SIZE = 1500000\n",
    "AVAILABLE_CPUS = cpu_count() - 1  # Disminuimos uno del total para evitar que la pc se queda inutilizable.\n",
    "INITIAL_VALID_COLUMNS = ['fare_amount',\n",
    "                         'pickup_datetime',\n",
    "                         'pickup_longitude',\n",
    "                         'pickup_latitude',\n",
    "                         'dropoff_longitude',\n",
    "                         'dropoff_latitude',\n",
    "                         'passenger_count'\n",
    "                         ]\n",
    "LIMIT_TO_TEST = 0\n",
    "\n",
    "FILE_PATH, EARTH_RADIUS, CHUNK_SIZE, AVAILABLE_CPUS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fórmula Haversine\n",
    "\n",
    "Esta fórmula nos servirá para poder calcular la distancia entre 2 puntos geográficos.\n",
    "\n",
    "$d=2r\\sin^{-1}{\\left(\\sqrt{\\sin^{2}{\\left(\\frac{\\phi_2-\\phi_1}{2}\\right)}+\\cos{(\\phi_1)}\\cos{(\\phi_2)}\\sin^{2}{\\left(\\frac{\\lambda_2-\\lambda_1}{2}\\right)} }\\right)}$\n",
    "\n",
    "Está fórmula será implementada en la función `calculate_haversine_distance`, la cual recibe una columna de tuplas con\n",
    "los puntos de latitud y longitud tanto de la posición en **pickup** como en **drop off**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def calculate_haversine_distance(pickup_position, drop_off_position):\n",
    "    pickup_lat, pickup_lng = pickup_position\n",
    "    drop_off_lat, drop_off_lng = drop_off_position\n",
    "\n",
    "    pickup_lat, pickup_lng, drop_off_lat, drop_off_lng = map(\n",
    "        radians,\n",
    "        (pickup_lat, pickup_lng, drop_off_lat, drop_off_lng)\n",
    "    )\n",
    "\n",
    "    lat_diff = drop_off_lat - pickup_lat\n",
    "    lng_diff = drop_off_lng - pickup_lng\n",
    "\n",
    "    distance = sin(lat_diff * 0.5) ** 2 + cos(pickup_lat) * cos(drop_off_lat) * sin(lng_diff * 0.5) ** 2\n",
    "\n",
    "    return 2 * EARTH_RADIUS * asin(sqrt(distance))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtener estados de hora y día\n",
    "\n",
    "Necesitamos utilizar las los datos de `pickup_datetime`, para ello, extraeremos en qué día de la semana y hora del día\n",
    "estamos. Usaremos los estados del día como día de la semana y fin de semana, que serán indicadores para predecir\n",
    "nuestro `fare_amount`. Además, extraeremos la hora del día, y lo separamos en sus respectivos estados: Madrugada,\n",
    "mañana, tarde y noche, que serán indicadores para predecir nuestro `fare_amount`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 0 si es fin de semana y 1 si es dia laboral\n",
    "def get_day_status(day):\n",
    "    weekends = [\"Saturday\", \"Sunday\"]\n",
    "    if day in weekends:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# 0 si es madrugada, 1 si es mañana\n",
    "# 2 si es tarde y 3 si es noche\n",
    "def get_time_status(hour):\n",
    "    hour_ = int(hour)\n",
    "    if hour_ < 6:\n",
    "        return 0\n",
    "    elif hour_ < 12:\n",
    "        return 1\n",
    "    elif hour_ < 18:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Procesamiento de la data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of rows: 55423857\n",
      "CPU times: user 7.92 s, sys: 2.52 s, total: 10.4 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Obtenemos el número de filas que tiene el archivo 'train.csv'\n",
    "with open(FILE_PATH) as file:\n",
    "    n_rows = len(file.readlines())\n",
    "\n",
    "print(\"Current number of rows: {}\".format(n_rows))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El dataset es enorme, tiene **55423857** registros sobre los precios de los taxis, dentro de este dataset tenemos casos\n",
    "donde no existen ciertos registros, o donde tenemos valores bastante extraños, tales como precios negativos o registros\n",
    "donde no existe ningún pasajero, estos registros pueden afectar enormemente los resultados de nuestro modelo, para ello\n",
    "es que debemos procesar la data y eliminar estos valores de nuestro dataset.\n",
    "\n",
    "Al ser un dataset tan grande el tiempo de cómputo necesario para procesar esta data en un solo hilo de nuestro\n",
    "procesador es bastante alto, por lo que debemos paralelizar este proceso, y asegurarnos que se usen al máximo los\n",
    "recursos que tenemos disponibles en nuestra computadora.\n",
    "\n",
    "La librería **Pandas** nos ofrece utilizar un proceso llamado **chunking** que consiste en dividir un gran dataset en\n",
    "pequeños trozos (**chunks**) esto lo logramos pasándole el parámetro `chunksize=(int)` al método `read_csv` de pandas,\n",
    "tal como se observa en la siguiente celda."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df_chunks = pd.read_csv(FILE_PATH, chunksize=CHUNK_SIZE, usecols=INITIAL_VALID_COLUMNS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En la celda anterior podemos observar que además de pasarle el parámetro `chunksize` al método `read_csv`.\n",
    "\n",
    "Otro parámetro pasado al método fue `usecols` el cual nos sirve para indicar que columnas queremos cargar en memoria.\n",
    "La columna `key` no es necesaria debido a que es una copia de la columna `pickup_datetime`, podríamos eliminarla\n",
    "posteriormente pero en temas de memoria esa columna extra al ser del tipo `object` nos quita espacio innecesariamente."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Función de paralelización\n",
    "\n",
    "Como se mencionó anteriormente llevaremos el procesamiento del dataset de forma paralela para ello utilizaremos el\n",
    "módulo multiprocessing de python, específicamente la clase Pool que nos permitirá asignar un proceso a cada uno de\n",
    "los hilos disponibles."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Variable que guardará todos los resultados procesados en cada iteración.\n",
    "chunk_list = []\n",
    "\n",
    "def parallelize_chunk_processing(chunk, func):\n",
    "\n",
    "    # Dividimos cada chunk en partes más pequeñas que son las que serán procesadas por cada hilo del procesador\n",
    "    chunk_split = np.array_split(chunk, AVAILABLE_CPUS)\n",
    "\n",
    "    # Creamos un pool de n hilos donde n es el número asignado previamente a **AVAILABLE_CPUS**\n",
    "    pool = Pool(AVAILABLE_CPUS)\n",
    "\n",
    "    # Creamos un nuevo dataset a partir de los resultados procesados en cada hilo.\n",
    "    chunk = pd.concat(pool.map(func, chunk_split))\n",
    "\n",
    "    # Cerramos el pool y creamos una barrera con el método join\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    chunk_list.append(chunk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez definida la función de paralelización procedemos con el tratamiento del dataset, tras varias pruebas decidimos\n",
    "que se deben aplicar las siguientes modificaciones al dataset original.\n",
    "\n",
    "* Eliminar los `nan` detectados por pandas al cargar el `chunk`.\n",
    "* Eliminar los precios negativos (**Campo `fare_amount`**).\n",
    "* Eliminar los outliers de la cantidad de pasajeros en el `chunk`.\n",
    "* Convertir los objetos de **pickup_datetime** a datetime para utilizar sus propiedades.\n",
    "* Considerar únicamente los datos del año 2012 por ser el año que tiene mayor cantidad de datos.\n",
    "* Reemplazar los valores `zero` en las columnas que no deberían tener dicho valor con un valor nan, tales como\n",
    "**pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, passenger_count**.\n",
    "* Obtener la distancia entre los puntos de **pickup** y **drop off**.\n",
    "* Eliminar las columnas que ya no serán útiles y eliminar los valores `nan` creados por nosotros.\n",
    "* Agregar la columna `day_status` que indicará el estado del día en la semana.\n",
    "* Agregar la columna `time_status` que indicará el estado de la hora en el día.\n",
    "* Eliminar las columnas con las que ya hemos trabajado.\n",
    "\n",
    "Para todo esto definimos la función `process_chunk` que recibirá como parámetro el chunk de cada iteración."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def process_chunk(split_chunk: pd.DataFrame):\n",
    "    # Eliminamos los valores **nan** encontrados por pandas\n",
    "    split_chunk.dropna(inplace=True)\n",
    "\n",
    "    # Eliminamos los montos menores o iguales que no tienen sentido en nuestro dataset\n",
    "    split_chunk.drop(split_chunk[split_chunk.fare_amount <= 0].index, inplace=True)\n",
    "\n",
    "    # Eliminamos el número de pasajeros negativos y mayores a 7 que son considerados outliers\n",
    "    # El límite de 7 es debido a que consideramos 3 niños y 3 adultos en la parte trasera, y 1 adulto en el asiento\n",
    "    # del copiloto como máximo\n",
    "    split_chunk.drop(\n",
    "        split_chunk[(split_chunk.passenger_count <= 0) | (split_chunk.passenger_count >= 7)].index, inplace=True)\n",
    "\n",
    "    # Convertimos el object a datetime para acceder a las propiedades pertenecientes a este tipo de dato\n",
    "    split_chunk[\"pickup_datetime\"] = pd.to_datetime(split_chunk[\"pickup_datetime\"], format='%Y-%m-%d %H:%M:%S UTC')\n",
    "\n",
    "    # Elegimos únicamente los datos con año 2012 porque es el que tiene mayor cantidad de datos\n",
    "    # En pruebas anteriores obtuvimos los resultados siguientes:\n",
    "\n",
    "    # 2012 - 8487134\n",
    "    # 2013 - 8394925\n",
    "    # 2011 - 8353025\n",
    "    # 2009 - 8257986\n",
    "    # 2010 - 8017197\n",
    "    # 2014 - 7977361\n",
    "    # 2015 - 3742902\n",
    "\n",
    "    split_chunk.drop(split_chunk[split_chunk[\"pickup_datetime\"].dt.year != 2012].index, inplace=True)\n",
    "\n",
    "    # Volvemos **nan** aquellas columnas que no deben tener valores zero\n",
    "    to_nan_columns = [\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]\n",
    "    split_chunk[to_nan_columns] = split_chunk[to_nan_columns].replace(0, np.nan)\n",
    "\n",
    "    # Calculamos la distancia utilizando la fórmula Haversine\n",
    "    split_chunk['distance'] = split_chunk.apply(lambda row: calculate_haversine_distance(\n",
    "        pickup_position=(row[\"pickup_latitude\"], row[\"pickup_longitude\"]),\n",
    "        drop_off_position=(row[\"dropoff_latitude\"], row[\"dropoff_longitude\"])), axis=1)\n",
    "\n",
    "    # Eliminamos los todos los datos que tengan un valor **nan** de acuerdo a lo realizado previamente\n",
    "    split_chunk.dropna(inplace=True)\n",
    "\n",
    "    # Extraemos los días de la semana del datetime con %A\n",
    "    # Posteriormente aplicamos la función get_day_status para guardar el estado del día\n",
    "    split_chunk['day_status'] = split_chunk.apply(\n",
    "        lambda row: get_day_status(row.pickup_datetime.strftime(\"%A\")),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Extraemos la hora del día del datetime con %H.\n",
    "    # Posteriormente aplicamos la función get_time_status para guardar el estado de la hora.\n",
    "    split_chunk['time_status'] = split_chunk.apply(\n",
    "        lambda row: get_time_status(row.pickup_datetime.strftime(\"%H\")),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Eliminamos aquellas distancias menores a 0.1 km, debido a que nos parece que este debe ser nuestra mínimo aceptable\n",
    "    split_chunk.drop(split_chunk[split_chunk.distance <= 0.1].index, inplace=True)\n",
    "\n",
    "    # Eliminamos las columnas con las que ya hemos trabajado\n",
    "    split_chunk.drop([\"pickup_longitude\",\n",
    "                      \"pickup_latitude\",\n",
    "                      \"dropoff_longitude\",\n",
    "                      \"dropoff_latitude\",\n",
    "                      \"pickup_datetime\"],\n",
    "                     axis=1,\n",
    "                     inplace=True)\n",
    "\n",
    "    return split_chunk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ya tenemos definida la función que nos servirá para procesar el dataset, ahora deberemos iterar sobre el objeto\n",
    "`df_chunks` que inicializamos anteriormente."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [02:32,  4.12s/it]                        \n"
     ]
    }
   ],
   "source": [
    "processed_count = 0\n",
    "\n",
    "for df_chunk in tqdm(df_chunks, total=n_rows // CHUNK_SIZE):\n",
    "    parallelize_chunk_processing(df_chunk, process_chunk)\n",
    "\n",
    "    # Limitante para poder plotear algunas características\n",
    "    if processed_count >= LIMIT_TO_TEST != 0:\n",
    "        break\n",
    "\n",
    "    processed_count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cuando el proceso termine tendremos los resultados procesados en la variable `chunk_list` que es lo que utilizaremos\n",
    "para crear un nuevo dataframe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "    fare_amount  passenger_count  distance  day_status  time_status\n3           7.7                1  2.802346           0            0\n6           7.5                1  1.557516           1            3\n7          16.5                1  4.160010           1            2\n8           9.0                1  1.254608           1            2\n10          5.3                1  1.376087           0            1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fare_amount</th>\n      <th>passenger_count</th>\n      <th>distance</th>\n      <th>day_status</th>\n      <th>time_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>7.7</td>\n      <td>1</td>\n      <td>2.802346</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7.5</td>\n      <td>1</td>\n      <td>1.557516</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>16.5</td>\n      <td>1</td>\n      <td>4.160010</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.0</td>\n      <td>1</td>\n      <td>1.254608</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5.3</td>\n      <td>1</td>\n      <td>1.376087</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(chunk_list)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "        fare_amount  passenger_count      distance    day_status   time_status\ncount  8.487137e+06     8.487137e+06  8.487137e+06  8.487137e+06  8.487137e+06\nmean   1.114520e+01     1.699622e+00  8.622071e+00  7.134490e-01  1.845803e+00\nstd    9.191402e+00     1.336009e+00  1.716846e+02  4.521499e-01  1.039175e+00\nmin    2.500000e+00     1.000000e+00  1.000030e-01  0.000000e+00  0.000000e+00\n25%    6.000000e+00     1.000000e+00  1.319777e+00  0.000000e+00  1.000000e+00\n50%    8.500000e+00     1.000000e+00  2.246836e+00  1.000000e+00  2.000000e+00\n75%    1.250000e+01     2.000000e+00  4.070224e+00  1.000000e+00  3.000000e+00\nmax    4.750000e+02     6.000000e+00  1.971043e+04  1.000000e+00  3.000000e+00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fare_amount</th>\n      <th>passenger_count</th>\n      <th>distance</th>\n      <th>day_status</th>\n      <th>time_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8.487137e+06</td>\n      <td>8.487137e+06</td>\n      <td>8.487137e+06</td>\n      <td>8.487137e+06</td>\n      <td>8.487137e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.114520e+01</td>\n      <td>1.699622e+00</td>\n      <td>8.622071e+00</td>\n      <td>7.134490e-01</td>\n      <td>1.845803e+00</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.191402e+00</td>\n      <td>1.336009e+00</td>\n      <td>1.716846e+02</td>\n      <td>4.521499e-01</td>\n      <td>1.039175e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.500000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000030e-01</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.319777e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8.500000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.246836e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.000000e+00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.250000e+01</td>\n      <td>2.000000e+00</td>\n      <td>4.070224e+00</td>\n      <td>1.000000e+00</td>\n      <td>3.000000e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.750000e+02</td>\n      <td>6.000000e+00</td>\n      <td>1.971043e+04</td>\n      <td>1.000000e+00</td>\n      <td>3.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8487137 entries, 3 to 55423839\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   fare_amount      float64\n",
      " 1   passenger_count  int64  \n",
      " 2   distance         float64\n",
      " 3   day_status       int64  \n",
      " 4   time_status      int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 388.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
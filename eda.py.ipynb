{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Aplicando EDA al dataset Taxi Fare\n",
    "\n",
    "Instalamos las dependencias necesarias para realizar el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/parrot/Desktop/venv/lib/python3.8/site-packages (1.2.4)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from pandas) (2021.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from pandas) (2.8.1)\r\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from pandas) (1.20.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: seaborn in /home/parrot/Desktop/venv/lib/python3.8/site-packages (0.11.1)\r\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from seaborn) (3.4.2)\r\n",
      "Requirement already satisfied: pandas>=0.23 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from seaborn) (1.2.4)\r\n",
      "Requirement already satisfied: scipy>=1.0 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from seaborn) (1.6.3)\r\n",
      "Requirement already satisfied: numpy>=1.15 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from seaborn) (1.20.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\r\n",
      "Requirement already satisfied: six in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/parrot/Desktop/venv/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\r\n",
      "Requirement already satisfied: tqdm in /home/parrot/Desktop/venv/lib/python3.8/site-packages (4.61.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importamos los módulos a utilizar posteriormente\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# Esto es solo para la visualización en Pycharm\n",
    "sns.set_style(\"ticks\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inicializamos algunas constantes a utilizar\n",
    "\n",
    "* **FILE_PATH:** Contiene la ruta de nuestro dataset.\n",
    "* **EARTH_RADIUS:** Es el valor promedio del radio de la Tierra en kilómetros.\n",
    "* **CHUNK_SIZE:** Indica el tamaño del conjunto de datos que se procesará en cada iteración.\n",
    "* **AVAILABLE_CPUS:** Tiene el número de threads que estarán disponibles en el uso de este cuaderno.\n",
    "* **INITIAL_VALID_COLUMNS:** Tiene los nombres de las columnas que nos interesa cargar en memoria.\n",
    "* **LIMIT_TO_TEST:** El número de chunks que usaremos para realizar algunos gráficos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "('train.csv', 6378.0, 150000, 6)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_PATH = \"train.csv\"\n",
    "EARTH_RADIUS = 6378.0  # Lo utilizamos en el cálculo de la fórmula de Haversine.\n",
    "CHUNK_SIZE = 1500000\n",
    "AVAILABLE_CPUS = cpu_count() - 1  # Disminuimos uno del total para evitar que la pc se queda inutilizable.\n",
    "INITIAL_VALID_COLUMNS = ['fare_amount',\n",
    "                         'pickup_datetime',\n",
    "                         'pickup_longitude',\n",
    "                         'pickup_latitude',\n",
    "                         'dropoff_longitude',\n",
    "                         'dropoff_latitude',\n",
    "                         'passenger_count'\n",
    "                         ]\n",
    "LIMIT_TO_TEST = 0\n",
    "\n",
    "FILE_PATH, EARTH_RADIUS, CHUNK_SIZE, AVAILABLE_CPUS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fórmula Haversine\n",
    "\n",
    "Esta fórmula nos servirá para poder calcular la distancia entre 2 puntos geográficos.\n",
    "\n",
    "$d=2r\\sin^{-1}{\\left(\\sqrt{\\sin^{2}{\\left(\\frac{\\phi_2-\\phi_1}{2}\\right)}+\\cos{(\\phi_1)}\\cos{(\\phi_2)}\\sin^{2}{\\left(\\frac{\\lambda_2-\\lambda_1}{2}\\right)} }\\right)}$\n",
    "\n",
    "Está fórmula será implementada en la función `calculate_haversine_distance`, la cual recibe una columna de tuplas con\n",
    "los puntos de latitud y longitud tanto de la posición en **pickup** como en **drop off**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def calculate_haversine_distance(pickup_position, drop_off_position):\n",
    "    pickup_lat, pickup_lng = pickup_position\n",
    "    drop_off_lat, drop_off_lng = drop_off_position\n",
    "\n",
    "    pickup_lat, pickup_lng, drop_off_lat, drop_off_lng = map(\n",
    "        radians,\n",
    "        (pickup_lat, pickup_lng, drop_off_lat, drop_off_lng)\n",
    "    )\n",
    "\n",
    "    lat_diff = drop_off_lat - pickup_lat\n",
    "    lng_diff = drop_off_lng - pickup_lng\n",
    "\n",
    "    distance = sin(lat_diff * 0.5) ** 2 + cos(pickup_lat) * cos(drop_off_lat) * sin(lng_diff * 0.5) ** 2\n",
    "\n",
    "    return 2 * EARTH_RADIUS * asin(sqrt(distance))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtener estados de hora y día\n",
    "\n",
    "Necesitamos utilizar las los datos de `pickup_datetime`, para ello, extraeremos en qué día de la semana y hora del día\n",
    "estamos. Usaremos los estados del día como día de la semana y fin de semana, que serán indicadores para predecir\n",
    "nuestro `fare_amount`. Además, extraeremos la hora del día, y lo separamos en sus respectivos estados: Madrugada,\n",
    "mañana, tarde y noche, que serán indicadores para predecir nuestro `fare_amount`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 0 si es fin de semana y 1 si es dia laboral\n",
    "def get_day_status(day):\n",
    "    weekends = [\"Saturday\", \"Sunday\"]\n",
    "    if day in weekends:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# 0 si es madrugada, 1 si es mañana\n",
    "# 2 si es tarde y 3 si es noche\n",
    "def get_time_status(hour):\n",
    "    hour_ = int(hour)\n",
    "    if hour_ < 6:\n",
    "        return 0\n",
    "    elif hour_ < 12:\n",
    "        return 1\n",
    "    elif hour_ < 18:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Procesamiento de la data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of rows: 55423857\n",
      "CPU times: user 10.6 s, sys: 6.56 s, total: 17.1 s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Obtenemos el número de filas que tiene el archivo 'train.csv'\n",
    "with open(FILE_PATH) as file:\n",
    "    n_rows = len(file.readlines())\n",
    "\n",
    "print(\"Current number of rows: {}\".format(n_rows))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El dataset es enorme, tiene **55423857** registros sobre los precios de los taxis, dentro de este dataset tenemos casos\n",
    "donde no existen ciertos registros, o donde tenemos valores bastante extraños, tales como precios negativos o registros\n",
    "donde no existe ningún pasajero, estos registros pueden afectar enormemente los resultados de nuestro modelo, para ello\n",
    "es que debemos procesar la data y eliminar estos valores de nuestro dataset.\n",
    "\n",
    "Al ser un dataset tan grande el tiempo de cómputo necesario para procesar esta data en un solo hilo de nuestro\n",
    "procesador es bastante alto, por lo que debemos paralelizar este proceso, y asegurarnos que se usen al máximo los\n",
    "recursos que tenemos disponibles en nuestra computadora.\n",
    "\n",
    "La librería **Pandas** nos ofrece utilizar un proceso llamado **chunking** que consiste en dividir un gran dataset en\n",
    "pequeños trozos (**chunks**) esto lo logramos pasándole el parámetro `chunksize=(int)` al método `read_csv` de pandas,\n",
    "tal como se observa en la siguiente celda."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_chunks = pd.read_csv(FILE_PATH, chunksize=CHUNK_SIZE, usecols=INITIAL_VALID_COLUMNS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En la celda anterior podemos observar que además de pasarle el parámetro `chunksize` al método `read_csv`.\n",
    "\n",
    "Otro parámetro pasado al método fue `usecols` el cual nos sirve para indicar que columnas queremos cargar en memoria.\n",
    "La columna `key` no es necesaria debido a que es una copia de la columna `pickup_datetime`, podríamos eliminarla\n",
    "posteriormente pero en temas de memoria esa columna extra al ser del tipo `object` nos quita espacio innecesariamente."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Función de paralelización\n",
    "\n",
    "Como se mencionó anteriormente llevaremos el procesamiento del dataset de forma paralela para ello utilizaremos el\n",
    "módulo multiprocessing de python, específicamente la clase Pool que nos permitirá asignar un proceso a cada uno de\n",
    "los hilos disponibles."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Variable que guardará todos los resultados procesados en cada iteración.\n",
    "chunk_list = []\n",
    "\n",
    "def parallelize_chunk_processing(chunk, func):\n",
    "\n",
    "    # Dividimos cada chunk en partes más pequeñas que son las que serán procesadas por cada hilo del procesador\n",
    "    chunk_split = np.array_split(chunk, AVAILABLE_CPUS)\n",
    "\n",
    "    # Creamos un pool de n hilos donde n es el número asignado previamente a **AVAILABLE_CPUS**\n",
    "    pool = Pool(AVAILABLE_CPUS)\n",
    "\n",
    "    # Creamos un nuevo dataset a partir de los resultados procesados en cada hilo.\n",
    "    chunk = pd.concat(pool.map(func, chunk_split))\n",
    "\n",
    "    # Cerramos el pool y creamos una barrera con el método join\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    chunk_list.append(chunk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez definida la función de paralelización procedemos con el tratamiento del dataset, tras varias pruebas decidimos\n",
    "que se deben aplicar las siguientes modificaciones al dataset original.\n",
    "\n",
    "* Eliminar los `nan` detectados por pandas al cargar el `chunk`\n",
    "* Reemplazar los valores `zero` en las columnas que no deberían tener dicho valor con un valor nan, tales como\n",
    "**pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, passenger_count**.\n",
    "* Obtener la distancia entre los puntos de **pickup** y **drop off**.\n",
    "* Eliminar las columnas que ya no serán útiles y eliminar los valores `nan` creados por nosotros.\n",
    "* Eliminar los precios negativos (**Campo `fare_amount`**)\n",
    "* **TODO** Agregar más cosas a procesar, ya sea al final o entre los otros pasos.\n",
    "\n",
    "Para todo esto definimos la función `process_chunk` que recibirá como parámetro el chunk de cada iteración."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def process_chunk(split_chunk: pd.DataFrame):\n",
    "    # Eliminamos los valores nan encontrados por pandas\n",
    "    split_chunk.dropna(inplace=True)\n",
    "\n",
    "    # Volvemos **nan** aquellas columnas que no deben tener valores zero\n",
    "    to_nan_columns = [\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\", \"passenger_count\"]\n",
    "    split_chunk[to_nan_columns] = split_chunk[to_nan_columns].replace(0, np.nan)\n",
    "\n",
    "    # Calculamos la distancia utilizando la fórmula Haversine\n",
    "    split_chunk['distance'] = split_chunk.apply(lambda row: calculate_haversine_distance(\n",
    "        pickup_position=(row[\"pickup_latitude\"], row[\"pickup_longitude\"]),\n",
    "        drop_off_position=(row[\"dropoff_latitude\"], row[\"dropoff_longitude\"])), axis=1)\n",
    "\n",
    "    # Convertimos el object a datetime para reducir el tiempo de ejecución al obtener el día y la hora \n",
    "    split_chunk[\"pickup_datetime\"] = pd.to_datetime(split_chunk[\"pickup_datetime\"], format='%Y-%m-%d %H:%M:%S UTC')\n",
    "\n",
    "    # Extraemos los días de la semana del datetime con %A\n",
    "    # Posteriormente aplicamos la función get_day_status para guardar el estado del día\n",
    "    split_chunk['day_status'] = split_chunk.apply(\n",
    "        lambda row: get_day_status(row.pickup_datetime.strftime(\"%A\")),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Extraemos la hora del día del datetime con %H.\n",
    "    # Posteriormente aplicamos la función get_time_status para guardar el estado de la hora.\n",
    "    split_chunk['time_status'] = split_chunk.apply(\n",
    "        lambda row: get_time_status(row.pickup_datetime.strftime(\"%H\")),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Volvemos **nan** aquellas distancias con valor cero\n",
    "    split_chunk[\"distance\"] = split_chunk[\"distance\"].replace(0, np.nan)\n",
    "\n",
    "    split_chunk.dropna(inplace=True)\n",
    "    split_chunk.drop([\"pickup_longitude\",\n",
    "                      \"pickup_latitude\",\n",
    "                      \"dropoff_longitude\",\n",
    "                      \"dropoff_latitude\",\n",
    "                      \"pickup_datetime\"],\n",
    "                     axis=1,\n",
    "                     inplace=True)\n",
    "\n",
    "    split_chunk.drop(split_chunk[split_chunk.distance <= 0.1].index, inplace=True)\n",
    "    split_chunk.drop(split_chunk[split_chunk.fare_amount <= 0].index, inplace=True)\n",
    "    split_chunk.drop(\n",
    "        split_chunk[(split_chunk.passenger_count <= 0) | (split_chunk.passenger_count >= 7)].index, inplace=True)\n",
    "\n",
    "    return split_chunk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ya tenemos definida la función que nos servirá para procesar el dataset, ahora deberemos iterar sobre el objeto\n",
    "`df_chunks` que inicializamos anteriormente."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/369 [00:53<5:25:08, 53.01s/it]\n"
     ]
    }
   ],
   "source": [
    "processed_count = 0\n",
    "\n",
    "for df_chunk in tqdm(df_chunks, total=n_rows // CHUNK_SIZE):\n",
    "    parallelize_chunk_processing(df_chunk, process_chunk)\n",
    "\n",
    "    # Limitante para poder plotear algunas características\n",
    "    if processed_count >= LIMIT_TO_TEST != 0:\n",
    "        break\n",
    "\n",
    "    processed_count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cuando el proceso termine tendremos los resultados procesados en la variable `chunk_list` que es lo que utilizaremos\n",
    "para crear un nuevo dataframe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   fare_amount  passenger_count  distance  day_status  time_status\n0          4.5              1.0  1.031896           1            2\n1         16.9              1.0  8.459418           1            2\n2          5.7              2.0  1.391052           1            0\n3          7.7              1.0  2.802346           0            0\n4          5.3              1.0  2.001353           1            1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fare_amount</th>\n      <th>passenger_count</th>\n      <th>distance</th>\n      <th>day_status</th>\n      <th>time_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.5</td>\n      <td>1.0</td>\n      <td>1.031896</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16.9</td>\n      <td>1.0</td>\n      <td>8.459418</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.7</td>\n      <td>2.0</td>\n      <td>1.391052</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.7</td>\n      <td>1.0</td>\n      <td>2.802346</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.3</td>\n      <td>1.0</td>\n      <td>2.001353</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(chunk_list)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "         fare_amount  passenger_count       distance     day_status  \\\ncount  288140.000000    288140.000000  288140.000000  288140.000000   \nmean       11.319978         1.692365       4.351984       0.717162   \nstd         9.552434         1.308867      71.979275       0.450379   \nmin         0.010000         1.000000       0.100068       0.000000   \n25%         6.000000         1.000000       1.296206       0.000000   \n50%         8.500000         1.000000       2.198208       1.000000   \n75%        12.500000         2.000000       3.981496       1.000000   \nmax       495.000000         6.000000   10954.538494       1.000000   \n\n         time_status  \ncount  288140.000000  \nmean        1.848227  \nstd         1.035528  \nmin         0.000000  \n25%         1.000000  \n50%         2.000000  \n75%         3.000000  \nmax         3.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fare_amount</th>\n      <th>passenger_count</th>\n      <th>distance</th>\n      <th>day_status</th>\n      <th>time_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>288140.000000</td>\n      <td>288140.000000</td>\n      <td>288140.000000</td>\n      <td>288140.000000</td>\n      <td>288140.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>11.319978</td>\n      <td>1.692365</td>\n      <td>4.351984</td>\n      <td>0.717162</td>\n      <td>1.848227</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.552434</td>\n      <td>1.308867</td>\n      <td>71.979275</td>\n      <td>0.450379</td>\n      <td>1.035528</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.010000</td>\n      <td>1.000000</td>\n      <td>0.100068</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.000000</td>\n      <td>1.000000</td>\n      <td>1.296206</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8.500000</td>\n      <td>1.000000</td>\n      <td>2.198208</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>12.500000</td>\n      <td>2.000000</td>\n      <td>3.981496</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>495.000000</td>\n      <td>6.000000</td>\n      <td>10954.538494</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 288140 entries, 0 to 299999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   fare_amount      288140 non-null  float64\n",
      " 1   passenger_count  288140 non-null  float64\n",
      " 2   distance         288140 non-null  float64\n",
      " 3   day_status       288140 non-null  int64  \n",
      " 4   time_status      288140 non-null  int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 13.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0    199890\n2.0     42773\n5.0     20556\n3.0     12628\n6.0      6183\n4.0      6110\nName: passenger_count, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"passenger_count\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "1.365033    2\n0.571612    1\n1.132652    1\n1.030655    1\n1.585141    1\n           ..\n1.390321    1\n0.943104    1\n5.541551    1\n3.342721    1\n1.324846    1\nName: distance, Length: 288139, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"distance\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}